// This file allows the user to drag and create a bounding box around the object that they wish to track (replicates user uploaded image in a way)
// The bounding box is then saved as an image to the desktop (can change filepath if necessary) and that image is read in by the image processing code
// You may want to disable camshift tracking and replace it with a simple bounding box that does not move if it is difficult to get a good box for
// a template match. Backprojection can be seen by pressing 'b' after creating bounding box. This may be helpful in understanding what values are
// needed for a good match of the object given the conditions. All same logic of tracking in the other code applies here as well (adjusting sliders,
// etc.).

#include <opencv2/core/utility.hpp>
#include "opencv2/video/tracking.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include "opencv2/highgui.hpp"

#include <iostream>
#include <ctype.h>
#include <chrono>

using namespace cv;
using namespace std;

Mat image;

bool backprojMode = false;
bool selectObject = false;
int previous_selection_height = 0;
bool new_selection = false;
bool FirstImage = false;
auto start = std::chrono::high_resolution_clock::now();
int trackObject = 0;
bool showHist = true;
Point origin;
Rect selection;
int vmin = 20, vmax = 256, smin = 170;
// focal_length = focal length given by manufacturer in mm. 
// f_x and f_y values (pixels) in CameraMatrix output that was generated by CameraCalibration code are same value so I simplified to just f.
// actual_object_height is the real world height of the object in mm. Hardcoded for testing purposes.
double focal_length = 2.1, f = 396.83218974894680, actual_object_height = 860;
// camera resolution is 1920x1080. Aspect ratio is 640x480.
int camera_resolution_x = 640, camera_resolution_y = 480, aspect_ratio_x = 640, aspect_ratio_y = 480;
// scaling factor that scales the camera calibration focal length to the manufacturer focal length
double scale_factor = f / focal_length;
// pixels/mm after being scaled down to the 640x480 aspect ratio
double scaled_px_per_mm = (aspect_ratio_x * scale_factor) / camera_resolution_x;

// Constants determined from camera calibration to eliminate fisheye distortion
Mat cameraMatrix = (Mat_<double>(3, 3) << 3.9683218974894680e+02, 0., 3.1950000000000000e+02, 0.,
	3.9683218974894680e+02, 2.3950000000000000e+02, 0., 0., 1.);
Mat distCoeffs = (Mat_<double>(5, 1) << -4.5596899020020748e-01, 2.5706133556827276e-01, 0., 0.,
	-7.4662921360934026e-02);
Mat R, map1, map2, undistortedframe;

// Draws user selected bounding box
static void onMouse( int event, int x, int y, int, void* )
{
    // Dimensions bounding box parameters after object selection is determined
	if( selectObject )
    {
        selection.x = MIN(x, origin.x);
        selection.y = MIN(y, origin.y);
        selection.width = std::abs(x - origin.x);
        selection.height = std::abs(y - origin.y);

        selection &= Rect(0, 0, image.cols, image.rows);
    }

    switch( event )
    {
    // Left mouse click is being held down
	case EVENT_LBUTTONDOWN:
        origin = Point(x,y);
        selection = Rect(x,y,0,0);
        selectObject = true;
		new_selection = false;
        break;
    // Left mouse click is no longer being held down
	case EVENT_LBUTTONUP:
        selectObject = false;
        if( selection.width > 0 && selection.height > 0 )
			new_selection = true;
            trackObject = -1;
        break;
    }
}

string hot_keys =
    "\n\nHot keys: \n"
    "\tESC - quit the program\n"
    "\tc - stop the tracking\n"
    "\tb - switch to/from backprojection view\n"
    "\th - show/hide object histogram\n"
    "\tp - pause video\n"
    "To initialize tracking, select the object with mouse\n";

static void help()
{
    cout << "\nThis is a demo that shows mean-shift based tracking\n"
            "You select a color objects such as your face and it tracks it.\n"
            "This reads from video camera (0 by default, or the camera number the user enters\n"
            "Usage: \n"
            "   ./camshiftdemo [camera number]\n";
    cout << hot_keys;
}

const char* keys =
{
    "{help h | | show help message}{@camera_number| 0 | camera number}"
};

int main( int argc, const char** argv )
{
    VideoCapture cap;
    Rect trackWindow;
    int hsize = 16;
    float hranges[] = {0,180};
    const float* phranges = hranges;
    CommandLineParser parser(argc, argv, keys);
    if (parser.has("help"))
    {
        help();
        return 0;
    }
    int camNum = parser.get<int>(0);
    cap.open(1);

    if( !cap.isOpened() )
    {
        help();
        cout << "***Could not initialize capturing...***\n";
        cout << "Current parameter's value: \n";
        parser.printMessage();
        return -1;
    }
    cout << hot_keys;
    namedWindow( "Histogram", 0 );
    namedWindow( "CamShift Demo", 0 );
    setMouseCallback( "CamShift Demo", onMouse, 0 );
    createTrackbar( "Vmin", "CamShift Demo", &vmin, 256, 0 );
    createTrackbar( "Vmax", "CamShift Demo", &vmax, 256, 0 );
    createTrackbar( "Smin", "CamShift Demo", &smin, 256, 0 );

	// Creates frame dimensions. Same as aspect ratio of camera
	int frame_width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	int frame_height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

	VideoWriter video("output.avi", CV_FOURCC('M', 'J', 'P', 'G'), 6, Size(frame_width, frame_height), true);
	Mat frame, hsv, hue, mask, hist, histimg = Mat::zeros(200, 320, CV_8UC3), backproj;
    bool paused = false;

    // Loop as long as video feed is established
	for(;;)
    {
        // Continue camera stream if not paused and display frames
		if( !paused )
        {
            cap >> frame;
            if( frame.empty() )
                break;
        }

		// Functions to remove fisheye distortion
		cv::initUndistortRectifyMap(cameraMatrix, distCoeffs, Matx33d::eye(), cameraMatrix, Size(640, 480), CV_16SC2, map1, map2);
		cv::remap(frame, undistortedframe, map1, map2, CV_INTER_LINEAR);
		undistortedframe.copyTo(image);
		//frame.copyTo(image);

        if( !paused )
        {
            cvtColor(image, hsv, COLOR_BGR2HSV);

            if( trackObject )
            {
                int _vmin = vmin, _vmax = vmax;

                inRange(hsv, Scalar(0, smin, MIN(_vmin,_vmax)),
                        Scalar(180, 256, MAX(_vmin, _vmax)), mask);
                int ch[] = {0, 0};
                hue.create(hsv.size(), hsv.depth());
                mixChannels(&hsv, 1, &hue, 1, ch, 1);

                if( trackObject < 0 )
                {
                    Mat roi(hue, selection), maskroi(mask, selection);
                    calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &phranges);
                    normalize(hist, hist, 0, 255, NORM_MINMAX);

                    trackWindow = selection;
                    trackObject = 1;

                    histimg = Scalar::all(0);
                    int binW = histimg.cols / hsize;
                    Mat buf(1, hsize, CV_8UC3);
                    for( int i = 0; i < hsize; i++ )
                        buf.at<Vec3b>(i) = Vec3b(saturate_cast<uchar>(i*180./hsize), 255, 255);
                    cvtColor(buf, buf, COLOR_HSV2BGR);

                    for( int i = 0; i < hsize; i++ )
                    {
                        int val = saturate_cast<int>(hist.at<float>(i)*histimg.rows/255);
                        rectangle( histimg, Point(i*binW,histimg.rows),
                                   Point((i+1)*binW,histimg.rows - val),
                                   Scalar(buf.at<Vec3b>(i)), -1, 8 );
                    }
                }

                calcBackProject(&hue, 1, 0, hist, backproj, &phranges);
                backproj &= mask;
                RotatedRect trackBox = CamShift(backproj, trackWindow,
                                    TermCriteria( TermCriteria::EPS | TermCriteria::COUNT, 10, 1 ));
                if( trackWindow.area() <= 1 )
                {
                    int cols = backproj.cols, rows = backproj.rows, r = (MIN(cols, rows) + 5)/6;
                    trackWindow = Rect(trackWindow.x - r, trackWindow.y - r,
                                       trackWindow.x + r, trackWindow.y + r) &
                                  Rect(0, 0, cols, rows);
                }

                if( backprojMode )
                    cvtColor( backproj, image, COLOR_GRAY2BGR );
                // Draws an ellipse around the tracked object
				ellipse(image, trackBox, Scalar(0, 0, 255), 3, LINE_AA );
				new_selection = true;
            }
        }
        else if( trackObject < 0 )
            paused = false;

        if( selectObject && selection.width > 0 && selection.height > 0 )
        {
            Mat roi(image, selection);
            bitwise_not(roi, roi);
        }

		//video.write(image);
		// Determines the object height in pixels as it appears in the image
		double object_height_image = selection.height / scaled_px_per_mm;
		// distance from object to camera in mm
		double distance = (actual_object_height * focal_length) / object_height_image;
		// Statement to detect changes in image parameters. This is only for testing purposes to make sure the proper variables are being updated correctly.
		if (previous_selection_height != trackWindow.height && new_selection == true)
		{
			cout << "Height of object in image is: " << trackWindow.height << " pixels" << endl;
			cout << "Left most bounded box location is " << trackWindow.x << " pixels" << endl;
			//cout << "Distance from object to camera is: " << distance << " mm" << endl;
			previous_selection_height = trackWindow.height;
		}
		// Displays image of only the trackbox region of interest
		if (trackWindow.area() > 0 )
		{
			Mat image2 = Mat(image, trackWindow);
			imshow("ROI", image2);
			//Save image to desktop
			imwrite("C:/Users/Public/Desktop/Test.jpg", image2);
		}
		// Displays original image from camera capture
		imshow( "CamShift Demo", image );
        imshow( "Histogram", histimg );

		// Grabs another time measurement after code iterates. Determines the time elapsed through one iteration of the code by subtracting time
		// elapsed from timer start to end timer
		if (FirstImage = true)
		{
			auto diff = std::chrono::high_resolution_clock::now() - start;
			auto t1 = std::chrono::duration_cast<std::chrono::nanoseconds>(diff);
			cout << std::chrono::duration_cast<std::chrono::milliseconds>(diff).count() << " ms" << endl;
		}
		bool FirstImage = true;

		// Starts timer for how long a code takes to iterate
		start = std::chrono::high_resolution_clock::now();

        // If esc key is pressed, terminates program
		char c = (char)waitKey(1);
        if( c == 27 )
            break;
        switch(c)
        {
        case 'b':
            backprojMode = !backprojMode;
            break;
        case 'c':
            trackObject = 0;
            histimg = Scalar::all(0);
            break;
        case 'h':
            showHist = !showHist;
            if( !showHist )
                destroyWindow( "Histogram" );
            else
                namedWindow( "Histogram", 1 );
            break;
        case 'p':
            paused = !paused;
            break;
        default:
            ;
        }
    }

    return 0;
}
